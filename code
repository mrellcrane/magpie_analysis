# --- Imports ---
import pandas as pd
import json
import seaborn as sns
import matplotlib.pyplot as plt

# --- File Constants ---
# Define file paths for input and output files for better maintainability
DATA_FILE = 'data.json'
SKILLS_FILE = 'skills.json'
PROFICIENCY_FILE = 'proficiency.json'
TIME_SERIES_OUTPUT_CSV = 'time-series.csv' # Outputting CSV as per section header, despite step 3 mentioning .json
PROFICIENCY_REPORT_OUTPUT_CSV = 'proficiency_report.csv'

# 1.1: Consumes raw data (data.json)
# Read the main data file which contains scores associated with skills
with open(DATA_FILE, 'r') as f:
    raw_data_content = json.load(f)

# Create a pandas DataFrame from the 'scores' list
df_raw = pd.DataFrame(raw_data_content['scores'])

# 1.2: Validates / cleanses raw data
# Basic Cleansing Step 1: Remove rows where the 'skill' identifier is missing (NaN)
df_cleaned = df_raw.dropna(subset=['skill']).copy() # Use .copy() to avoid potential SettingWithCopyWarning later

# Basic Cleansing Step 2: Convert the 'score' column to numeric type.
# Invalid parsing will be set as NaN (Not a Number).
df_cleaned['score'] = pd.to_numeric(df_cleaned['score'], errors='coerce')

# 1.3: Outputs to a time series in ascending order in a CSV (time-series.csv)
# Sort the DataFrame. The requirement asks for 'time series in ascending order'.
# We assume the original index of the DataFrame represents the time sequence,
# as no specific time column was mentioned or used in the original snippet.
# If a dedicated timestamp column exists (e.g., 'timestamp'), sort by that instead:
# df_timeseries_sorted = df_cleaned.sort_values(by='timestamp', ascending=True)
df_timeseries_sorted = df_cleaned.sort_index(ascending=True)

# Output the sorted data to a CSV file.
# The index is included in the CSV, assuming it represents the time sequence.
df_timeseries_sorted.to_csv(TIME_SERIES_OUTPUT_CSV, index=True)

# --- Requirement: Output a proficiency by skill CSV ---

# 2.1: Consumes raw data (data.json) - Already done above, loaded into df_raw.
# 2.2: Validates / cleanses raw data - Already done above, processed into df_cleaned.

# 2.3: Consume skills (skills.json) and proficiency (proficiency.json)
# Read the skills definition file
with open(SKILLS_FILE, 'r') as f:
    skills_data_content = json.load(f)
# Extract the list of skills, using .get for safety if key might be missing
skills_list = skills_data_content.get('skills', [])

# Read the proficiency definition file (although its direct use isn't shown in calculation steps)
with open(PROFICIENCY_FILE, 'r') as f:
    proficiency_data_content = json.load(f)
# Extract the proficiency information, using .get for safety
proficiency_list = proficiency_data_content.get('proficiency', [])

# Note: skills_list and proficiency_list are loaded as per requirement 2.3.
# However, the subsequent calculation steps (2.4, 2.5) and the provided example
# rely solely on aggregating the 'score' column from data.json (df_cleaned).
# These lists might be intended for other validation or enrichment steps not explicitly requested here.

# 2.4: For each skill, calculate the number of records.
# 2.5: For each skill, calculate the average proficiency.

# We'll use the cleaned DataFrame (df_cleaned) where 'score' is numeric.
# Group the DataFrame by the 'skill' column.
# Then, aggregate to calculate both the count (number of records) and the mean (average proficiency/score).
proficiency_summary = df_cleaned.groupby('skill').agg(
    number_of_records=('skill', 'size'),  # Calculate count for each skill group (Requirement 2.4)
    average_proficiency=('score', 'mean') # Calculate mean score for each skill group (Requirement 2.5)
)

# 2.6: Output to a CSV a report of skill, number of records, average proficiency.
# Reset the index so that 'skill' becomes a regular column instead of the index.
# This matches the structure implied by the example "K, 2, 8".
proficiency_summary_output = proficiency_summary.reset_index()

# Output the resulting summary DataFrame to the specified CSV file.
# index=False prevents pandas from writing the DataFrame index as a column in the CSV.
proficiency_summary_output.to_csv(PROFICIENCY_REPORT_OUTPUT_CSV, index=False)

df_sorted = df_report.sort_values(by='skill')  # Sort by skill if desired

fig, ax1 = plt.subplots(figsize=(12, 8))
sns.set_theme(style="whitegrid")

# Bar chart for average_proficiency
sns.barplot(
    data=df_sorted,
    x='skill',
    y='average_proficiency',
    color='skyblue',
    ax=ax1
)

ax1.set_xlabel('Skill', fontsize=12)
ax1.set_ylabel('Average Proficiency Score', fontsize=12, color='blue')
ax1.tick_params(axis='y', labelcolor='blue')

# Create a second axis that shares the same x-axis
ax2 = ax1.twinx()

# Line chart for number_of_records
sns.lineplot(
    data=df_sorted,
    x='skill',
    y='number_of_records',
    color='red',
    marker='o',
    ax=ax2
)

ax2.set_ylabel('Number of Records', fontsize=12, color='red')
ax2.tick_params(axis='y', labelcolor='red')

plt.title('Skill Proficiency Analysis: Average Score vs. Number of Records', fontsize=16)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.savefig('dual_axis_visualization.png')
plt.show()
